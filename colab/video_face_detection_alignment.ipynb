{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распознавание лиц для видео\n",
    "Изображения обнаруженных лиц имеют формат `frameXfaceY.jpg`,\n",
    "где `X` представляет X кадр, а `Y` - Y лицо в X-м кадре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from matplotlib import pyplot as plt\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umeyama import umeyama\n",
    "from detector import mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RATIO_LANDMARKS = [\n",
    "    (0.31339227236234224, 0.3259269274198092),\n",
    "    (0.31075140146108776, 0.7228453709528997),\n",
    "    (0.5523683107816256, 0.5187296867370605),\n",
    "    (0.7752419985257663, 0.37262483743520886),\n",
    "    (0.7759613623985877, 0.6772957581740159)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте MTCNN и его функции forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = \"./mtcnn_weights/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mtcnn(session, model_path):\n",
    "    if not model_path:\n",
    "        model_path, _ = os.path.split(os.path.realpath(__file__))\n",
    "\n",
    "    with tf.variable_scope('pnet2'):\n",
    "        data = Input((None, None, None, 3), dtype=tf.float32, name='input')\n",
    "        pnet_ = mtcnn.PNet({'data': data})\n",
    "        pnet_.load(os.path.join(model_path, 'det1.npy'), session)\n",
    "    with tf.variable_scope('rnet2'):\n",
    "        data = Input((None, 24, 24, 3), tf.float32, 'input')\n",
    "        rnet_ = mtcnn.RNet({'data': data})\n",
    "        rnet_.load(os.path.join(model_path, 'det2.npy'), session)\n",
    "    with tf.variable_scope('onet2'):\n",
    "        data = Input((None, 48, 48, 3), tf.float32, 'input')\n",
    "        onet_ = mtcnn.ONet({'data': data})\n",
    "        onet_.load(os.path.join(model_path, 'det3.npy'), session)\n",
    "    return pnet_, rnet_, onet_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "with sess.as_default():\n",
    "    global pnet, rnet, onet\n",
    "    pnet, rnet, onet = create_mtcnn(sess, WEIGHTS_PATH)\n",
    "    pass\n",
    "\n",
    "global pnet, rnet, onet\n",
    "\n",
    "pnet = K.function(\n",
    "    [pnet.layers['data']],\n",
    "    [pnet.layers['conv4-2'], pnet.layers['prob1']]\n",
    ")\n",
    "rnet = K.function(\n",
    "    [rnet.layers['data']],\n",
    "    [rnet.layers['conv5-2'], rnet.layers['prob1']]\n",
    ")\n",
    "onet = K.function(\n",
    "    [onet.layers['data']],\n",
    "    [onet.layers['conv6-2'], onet.layers['conv6-3'], onet.layers['prob1']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте папку, в которую будут сохраняться изображения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Устанавливаем глобальные константы для путей сохранения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "FACES_PATH=\"/content/drive/MyDrive/faces\"\n",
    "\n",
    "DIR_FACES_ALGN = f\"{FACES_PATH}/aligned_faces\"\n",
    "DIR_FACES_RAW=f\"{FACES_PATH}/raw_faces\"\n",
    "DIR_FACES_BME=f\"{FACES_PATH}/binary_masks_eyes\"\n",
    "\n",
    "Path(DIR_FACES_ALGN).mkdir(parents=True, exist_ok=True)\n",
    "Path(DIR_FACES_RAW).mkdir(parents=True, exist_ok=True)\n",
    "Path(DIR_FACES_BME).mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для обработки видео и выравнивания лиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src_landmarks(x0, x1, y0, y1, pnts):\n",
    "    \"\"\"\n",
    "    x0, x1, y0, y1: (smoothed) bbox coord.\n",
    "    pnts: landmarks predicted by MTCNN\n",
    "    \"\"\"\n",
    "    src_landmarks = [(int(pnts[i + 5][0] - x0),\n",
    "                      int(pnts[i][0] - y0)) for i in range(5)]\n",
    "    return src_landmarks\n",
    "\n",
    "\n",
    "def get_tar_landmarks(img):\n",
    "    \"\"\"    \n",
    "    img: detected face image\n",
    "    \"\"\"\n",
    "    img_size = img.shape\n",
    "    tar_landmarks = [(int(xy[0] * img_size[0]),\n",
    "                      int(xy[1] * img_size[1])) for xy in RATIO_LANDMARKS]\n",
    "    return tar_landmarks\n",
    "\n",
    "\n",
    "def landmarks_match_mtcnn(src_im, src_landmarks, tar_landmarks):\n",
    "    \"\"\"\n",
    "    umeyama(src, dst, estimate_scale)\n",
    "    landmarks coord. for umeyama should be (width, height) or (y, x)\n",
    "    \"\"\"\n",
    "    src_size = src_im.shape\n",
    "    src_tmp = [(int(xy[1]), int(xy[0])) for xy in src_landmarks]\n",
    "    tar_tmp = [(int(xy[1]), int(xy[0])) for xy in tar_landmarks]\n",
    "    M = umeyama(np.array(src_tmp), np.array(tar_tmp), True)[0:2]\n",
    "    result = cv2.warpAffine(src_im, M, (src_size[1], src_size[0]), borderMode=cv2.BORDER_REPLICATE)\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_mtcnn_bbox(bboxes, im_shape):\n",
    "    \"\"\"\n",
    "    output bbox coordinate of MTCNN is (y0, x0, y1, x1)\n",
    "    Here we process the bbox coord. to a square bbox with ordering (x0, y1, x1, y0)\n",
    "    \"\"\"\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        y0, x0, y1, x1 = bboxes[i, 0:4]\n",
    "        w, h = int(y1 - y0), int(x1 - x0)\n",
    "        length = (w + h) / 2\n",
    "        center = (int((x1 + x0) / 2), int((y1 + y0) / 2))\n",
    "        new_x0 = np.max([0, (center[0] - length // 2)])  #.astype(np.int32)\n",
    "        new_x1 = np.min([im_shape[0], (center[0] + length // 2)])  #.astype(np.int32)\n",
    "        new_y0 = np.max([0, (center[1] - length // 2)])  #.astype(np.int32)\n",
    "        new_y1 = np.min([im_shape[1], (center[1] + length // 2)])  #.astype(np.int32)\n",
    "        bboxes[i, 0:4] = new_x0, new_y1, new_x1, new_y0\n",
    "        pass\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def process_video(input_img):\n",
    "    global frames, save_interval\n",
    "    global pnet, rnet, onet\n",
    "    minsize = 30  # minimum size of face\n",
    "    detec_threshold = 0.7\n",
    "    threshold = [0.6, 0.7, detec_threshold]  # three steps's threshold\n",
    "    factor = 0.709  # scale factor\n",
    "\n",
    "    frames += 1\n",
    "    if frames % save_interval == 0:\n",
    "        faces, pnts = mtcnn.detect_face(\n",
    "            input_img, minsize, pnet, rnet, onet, threshold, factor\n",
    "        )\n",
    "        faces = process_mtcnn_bbox(faces, input_img.shape)\n",
    "\n",
    "        for idx, (x0, y1, x1, y0, conf_score) in enumerate(faces):\n",
    "            det_face_im = input_img[int(x0):int(x1), int(y0):int(y1), :]\n",
    "\n",
    "            # get src/tar landmarks\n",
    "            src_landmarks = get_src_landmarks(x0, x1, y0, y1, pnts)\n",
    "            tar_landmarks = get_tar_landmarks(det_face_im)\n",
    "\n",
    "            # align detected face\n",
    "            aligned_det_face_im = landmarks_match_mtcnn(\n",
    "                det_face_im, src_landmarks, tar_landmarks)\n",
    "\n",
    "            fname = f\"{DIR_FACES_ALGN}/frame{frames}face{str(idx)}.jpg\"\n",
    "            plt.imsave(fname, aligned_det_face_im, format=\"jpg\")\n",
    "            fname = f\"{DIR_FACES_RAW}/frame{frames}face{str(idx)}.jpg\"\n",
    "            plt.imsave(fname, det_face_im, format=\"jpg\")\n",
    "\n",
    "            bm = np.zeros_like(aligned_det_face_im)\n",
    "            h, w = bm.shape[:2]\n",
    "            bm[int(src_landmarks[0][0] - h / 15):int(src_landmarks[0][0] + h / 15),\n",
    "            int(src_landmarks[0][1] - w / 8):int(src_landmarks[0][1] + w / 8), :] = 255\n",
    "            bm[int(src_landmarks[1][0] - h / 15):int(src_landmarks[1][0] + h / 15),\n",
    "            int(src_landmarks[1][1] - w / 8):int(src_landmarks[1][1] + w / 8), :] = 255\n",
    "            bm = landmarks_match_mtcnn(bm, src_landmarks, tar_landmarks)\n",
    "            fname = f\"{DIR_FACES_BME}/frame{frames}face{str(idx)}.jpg\"\n",
    "            plt.imsave(fname, bm, format=\"jpg\")\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "    return np.zeros((3, 3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начать распознавание лиц\n",
    "\n",
    "Имя файла входного видео по умолчанию: `source.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 0\n",
    "\n",
    "# configuration\n",
    "save_interval = 6  # perform face detection every {save_interval} frames\n",
    "fn_input_video = \"samples/source.mp4\"\n",
    "\n",
    "output = 'dummy.mp4'\n",
    "clip1 = VideoFileClip(fn_input_video)\n",
    "clip = clip1.fl_image(process_video)  #.subclip(0,3) #NOTE: this function expects color images!!\n",
    "clip.write_videofile(output, audio=False)\n",
    "clip1.reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Сохраненные изображения будут находиться в папке `faces/raw_faces` и `faces/aligned_faces` соответственно.\n",
    "## Бинарные маски будут находиться в `faces/binary_masks_eyes`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}