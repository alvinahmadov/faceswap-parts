{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# Импортируйте пакеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import *\n",
    "import keras.backend as K\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# Конфигурация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.set_learning_phase(1)\n",
    "#K.set_learning_phase(0) # set to 0 in inference phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of CPU cores\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "# Input/Output resolution\n",
    "RESOLUTION = 64  # 64x64, 128x128, 256x256\n",
    "assert (RESOLUTION % 64) == 0, \"Allowed values for RESOLUTION are 64, 128, or 256.\"\n",
    "\n",
    "# Batch size\n",
    "batch_size = 8\n",
    "assert (batch_size != 1 and batch_size % 2 == 0), \"Batch size should be an even number.\"\n",
    "\n",
    "# Use motion blur (data augmentation)\n",
    "# set True if training data contains images extracted from videos\n",
    "use_da_motion_blur = False\n",
    "\n",
    "# Use eye-aware training\n",
    "# require images generated from prep_binary_masks.ipynb\n",
    "use_bm_eyes = True\n",
    "\n",
    "# Probability of random color matching (data augmentation)\n",
    "prob_random_color_match = 0.5\n",
    "\n",
    "da_config = {\n",
    "    \"prob_random_color_match\": prob_random_color_match,\n",
    "    \"use_da_motion_blur\": use_da_motion_blur,\n",
    "    \"use_bm_eyes\": use_bm_eyes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to training images\n",
    "img_dir_src = './face_src/rgb' # source face\n",
    "img_dir_dst = './face_dst/rgb' # target face\n",
    "img_dir_src_bm_eyes = \"./face_src/binary_mask/faceA_eyes\"\n",
    "img_dir_dst_bm_eyes = \"./face_dst/binary_mask/faceB_eyes\"\n",
    "\n",
    "# Path to saved model weights\n",
    "models_dir = \"./models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture configuration\n",
    "arch_config = {\n",
    "    \"IMAGE_SHAPE\": (RESOLUTION, RESOLUTION, 3),\n",
    "    \"use_self_attn\": True,\n",
    "    \"norm\": \"instancenorm\",\n",
    "    \"model_capacity\": \"standard\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function weights configuration\n",
    "loss_weights = {\n",
    "    \"w_D\": 0.1,\n",
    "    \"w_recon\": 1.,\n",
    "    \"w_edge\": 0.1,\n",
    "    \"w_eyes\": 30.,\n",
    "    \"w_pl\": (0.01, 0.1, 0.3, 0.1)\n",
    "}\n",
    "\n",
    "# Init. loss config.\n",
    "loss_config = {\n",
    "    \"gan_training\": \"mixup_LSGAN\",\n",
    "    \"use_PL\": False,\n",
    "    \"PL_before_activ\": False,\n",
    "    \"use_mask_hinge_loss\": False,\n",
    "    \"m_mask\": 0.,\n",
    "    \"lr_factor\": 1.,\n",
    "    \"use_cyclic_loss\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# Определение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.faceswap_model import FaceswapModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = FaceswapModel(**arch_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# Загрузка весов моделей\n",
    "\n",
    "Имена файлов веса:\n",
    "```shell\n",
    "    encoder.h5\n",
    "    decoder_A.h5\n",
    "    deocder_B.h5\n",
    "    netDA.h5\n",
    "    netDB.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(path=models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Определите потери и создайте обучающие функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если выдает ошибки при создании vggface ResNet (возможно, из-за версии Keras), следующий код - это то, что мы сделали,\n",
    "чтобы сделать его доступным для работы в Colab.\n",
    "\n",
    "```shell\n",
    "!wget \"https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\"\n",
    "from colab.vggface_models import RESNET50\n",
    "\n",
    "vggface = RESNET50(include_top=False, weights=None, input_shape=(224, 224, 3))\n",
    "vggface.load_weights(\"rcmalli_vggface_tf_notop_resnet50.h5\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/rcmalli/keras-vggface\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "# VGGFace ResNet50\n",
    "vggface = VGGFace(include_top=False, model='resnet50', input_shape=(224, 224, 3))\n",
    "\n",
    "#vggface.summary()\n",
    "\n",
    "model.build_pl_model(vggface_model=vggface, before_activ=loss_config[\"PL_before_activ\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_train_functions(loss_weights=loss_weights, **loss_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='9'></a>\n",
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import showG, showG_mask, showG_eyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Начинайте обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create ./models directory\n",
    "Path(f\"models\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file names\n",
    "train_src = glob.glob(f\"{img_dir_src}/*.*\")\n",
    "train_dst = glob.glob(f\"{img_dir_dst}/*.*\")\n",
    "\n",
    "train_src_n_dst = train_src + train_dst\n",
    "\n",
    "assert len(train_src), f\"Изображение не найдено в {img_dir_src}\"\n",
    "assert len(train_dst), f\"Изображение не найдено в {img_dir_dst}\"\n",
    "print(f\"Количество изображений в папке A: {str(len(train_src))}\")\n",
    "print(f\"Количество изображений в папке B: {str(len(train_dst))}\")\n",
    "\n",
    "if use_bm_eyes:\n",
    "    assert len(glob.glob(img_dir_src_bm_eyes + \"/*.*\")), f\"Двоичная маска не найдена в {img_dir_src_bm_eyes}\"\n",
    "    assert len(glob.glob(img_dir_dst_bm_eyes + \"/*.*\")), f\"Двоичная маска не найдена в {img_dir_dst_bm_eyes}\"\n",
    "    \n",
    "    assert len(glob.glob(img_dir_src_bm_eyes + \"/*.*\")) == len(train_src), (\n",
    "        \"Количество изображений face_src не совпадает с количеством их двоичных масок. \"\n",
    "        \"Может быть вызвано любым файлом none изображения в папке.\"\n",
    "    )\n",
    "    assert len(glob.glob(img_dir_dst_bm_eyes + \"/*.*\")) == len(train_dst), (\n",
    "        \"Количество изображений face_dst не совпадает с количеством их двоичных масок. \"\n",
    "        \"Может быть вызвано любым файлом none изображения в папке.\"\n",
    "    )\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss_config(loss_conf):\n",
    "    for config, value in loss_conf.items():\n",
    "        print(f\"{config} = {value}\")\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random binary masks of eyes\n",
    "train_batch_src = DataLoader(filenames=train_src, all_filenames=train_src_n_dst,\n",
    "                             batch_size=batch_size, dir_bm_eyes=img_dir_src_bm_eyes,\n",
    "                             resolution=RESOLUTION, num_cpus=num_cpus, session=K.get_session(),\n",
    "                             **da_config)\n",
    "train_batch_dst = DataLoader(filenames=train_dst, all_filenames=train_src_n_dst,\n",
    "                             batch_size=batch_size, dir_bm_eyes=img_dir_dst_bm_eyes,\n",
    "                             resolution=RESOLUTION, num_cpus=num_cpus, session=K.get_session(),\n",
    "                             **da_config)\n",
    "_, t_src, bm_src = train_batch_src.get_next_batch()\n",
    "_, t_dst, bm_dst = train_batch_dst.get_next_batch()\n",
    "showG_eyes(t_src, t_dst, bm_src, bm_dst, batch_size)\n",
    "del train_batch_src, train_batch_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reset_session(save_path):\n",
    "    global model, vggface\n",
    "    global train_batch_src, train_batch_dst\n",
    "    model.save_weights(path=save_path)\n",
    "    del model\n",
    "    del vggface\n",
    "    del train_batch_src\n",
    "    del train_batch_dst\n",
    "    K.clear_session()\n",
    "    model = FaceswapModel(**arch_config)\n",
    "    model.load_weights(path=save_path)\n",
    "    vggface = VGGFace(include_top=False, model='resnet50', input_shape=(224, 224, 3))\n",
    "    model.build_pl_model(vggface_model=vggface, before_activ=loss_config[\"PL_before_activ\"])\n",
    "    train_batch_src = DataLoader(filenames=train_src, all_filenames=train_src_n_dst,\n",
    "                                 batch_size=batch_size, dir_bm_eyes=img_dir_src_bm_eyes,\n",
    "                                 resolution=RESOLUTION, num_cpus=num_cpus, session=K.get_session(),\n",
    "                                 **da_config)\n",
    "    train_batch_dst = DataLoader(filenames=train_dst, all_filenames=train_src_n_dst,\n",
    "                                 batch_size=batch_size, dir_bm_eyes=img_dir_dst_bm_eyes,\n",
    "                                 resolution=RESOLUTION, num_cpus=num_cpus, session=K.get_session(),\n",
    "                                 **da_config)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "t0 = time.time()\n",
    "\n",
    "# Resume training that was interrupted\n",
    "try:\n",
    "    gen_iterations\n",
    "    print(f\"Resume training from iter {gen_iterations}.\")\n",
    "except:\n",
    "    gen_iterations = 0\n",
    "\n",
    "errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n",
    "errGAs = {}\n",
    "errGBs = {}\n",
    "# Dictionaries are ordered in Python 3.6\n",
    "for k in ['ttl', 'adv', 'recon', 'edge', 'pl']:\n",
    "    errGAs[k] = 0\n",
    "    errGBs[k] = 0\n",
    "\n",
    "display_iters = 300\n",
    "backup_iters = 5000\n",
    "TOTAL_ITERS = 20000\n",
    "\n",
    "global train_batch_src, train_batch_dst\n",
    "\n",
    "train_batch_src = DataLoader(train_src, train_src_n_dst, batch_size,\n",
    "                             dir_bm_eyes=img_dir_src_bm_eyes, resolution=RESOLUTION,\n",
    "                             num_cpus=num_cpus, session=K.get_session(), **da_config)\n",
    "\n",
    "train_batch_dst = DataLoader(train_dst, train_src_n_dst, batch_size,\n",
    "                             dir_bm_eyes=img_dir_dst_bm_eyes, resolution=RESOLUTION,\n",
    "                             num_cpus=num_cpus, session=K.get_session(), **da_config)\n",
    "\n",
    "while gen_iterations <= TOTAL_ITERS:\n",
    "    # Loss function automation\n",
    "    if gen_iterations == (TOTAL_ITERS // 5 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = False\n",
    "        loss_config['m_mask'] = 0.0\n",
    "        reset_session(models_dir)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (TOTAL_ITERS // 5 + TOTAL_ITERS // 10 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = True\n",
    "        loss_config['m_mask'] = 0.5\n",
    "        reset_session(models_dir)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Завершено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (2 * TOTAL_ITERS // 5 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = True\n",
    "        loss_config['m_mask'] = 0.2\n",
    "        reset_session(models_dir)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (TOTAL_ITERS // 2 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = True\n",
    "        loss_config['m_mask'] = 0.4\n",
    "        loss_config['lr_factor'] = 0.3\n",
    "        reset_session(models_dir)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (2 * TOTAL_ITERS // 3 - display_iters // 2):\n",
    "        clear_output()\n",
    "        model.decoder_src.load_weights(\"models/decoder_B.h5\")  # swap decoders\n",
    "        model.decoder_dst.load_weights(\"models/decoder_A.h5\")  # swap decoders\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = True\n",
    "        loss_config['m_mask'] = 0.5\n",
    "        loss_config['lr_factor'] = 1\n",
    "        reset_session(models_dir)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (8 * TOTAL_ITERS // 10 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = True\n",
    "        loss_config['m_mask'] = 0.1\n",
    "        loss_config['lr_factor'] = 0.3\n",
    "        reset_session(models_dir)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (9 * TOTAL_ITERS // 10 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = False\n",
    "        loss_config['m_mask'] = 0.0\n",
    "        loss_config['lr_factor'] = 0.1\n",
    "        reset_session(models_dir)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "\n",
    "        pass\n",
    "\n",
    "    if gen_iterations == 5:\n",
    "        print(\"Выполняется.\")\n",
    "        pass\n",
    "\n",
    "    # Train dicriminators for one batch\n",
    "    data_src = train_batch_src.get_next_batch()\n",
    "    data_dst = train_batch_dst.get_next_batch()\n",
    "    errDA, errDB = model.train_one_batch_disc(data_src, data_dst)\n",
    "    errDA_sum += errDA[0]\n",
    "    errDB_sum += errDB[0]\n",
    "\n",
    "    # Train generators for one batch\n",
    "    data_src = train_batch_src.get_next_batch()\n",
    "    data_dst = train_batch_dst.get_next_batch()\n",
    "    errGA, errGB = model.train_one_batch_gen(data_src, data_dst)\n",
    "    errGA_sum += errGA[0]\n",
    "    errGB_sum += errGB[0]\n",
    "    for i, k in enumerate(['ttl', 'adv', 'recon', 'edge', 'pl']):\n",
    "        errGAs[k] += errGA[i]\n",
    "        errGBs[k] += errGB[i]\n",
    "        pass\n",
    "    gen_iterations += 1\n",
    "\n",
    "    # Visualization\n",
    "    if gen_iterations % display_iters == 0:\n",
    "        clear_output()\n",
    "\n",
    "        # Display loss information\n",
    "        show_loss_config(loss_config)\n",
    "        print(\"----------\")\n",
    "        print(\"[iter %d] Loss_DA: %f Loss_DB: %f Loss_GA: %f Loss_GB: %f time: %f\"\n",
    "              % (gen_iterations, errDA_sum / display_iters, errDB_sum / display_iters,\n",
    "                 errGA_sum / display_iters, errGB_sum / display_iters, time.time() - t0))\n",
    "        print(\"----------\")\n",
    "        print(\"Детали потерь генератора:\")\n",
    "        print(f\"[Adversarial loss]\\nGA: {errGAs['adv'] / display_iters:.4f} GB: {errGBs['adv'] / display_iters:.4f}\")\n",
    "        print(f\"[Reconstruction loss]\\nGA: {errGAs['recon'] / display_iters:.4f} GB: {errGBs['recon'] / display_iters:.4f}\")\n",
    "        print(f\"[Edge loss]\\nGA: {errGAs['edge'] / display_iters:.4f} GB: {errGBs['edge'] / display_iters:.4f}\")\n",
    "        if loss_config['use_PL']:\n",
    "            print(f\"[Perceptual loss]\")\n",
    "            try:\n",
    "                print(f\"GA: {errGAs['pl'][0] / display_iters:.4f} GB: {errGBs['pl'][0] / display_iters:.4f}\")\n",
    "            except:\n",
    "                print(f\"GA: {errGAs['pl'] / display_iters:.4f} GB: {errGBs['pl'] / display_iters:.4f}\")\n",
    "                pass\n",
    "            pass\n",
    "\n",
    "        # Display images\n",
    "        print(\"----------\")\n",
    "        w_src, t_src, _ = train_batch_src.get_next_batch()\n",
    "        w_dst, t_dst, _ = train_batch_dst.get_next_batch()\n",
    "        print(\"Преобразованные (замаскированные) результаты:\")\n",
    "        showG(t_src, t_dst, model.path_src, model.path_dst, batch_size)\n",
    "        print(\"Маски:\")\n",
    "        showG_mask(t_src, t_dst, model.path_mask_src, model.path_mask_dst, batch_size)\n",
    "        print(\"Результаты реконструкции:\")\n",
    "        showG(w_src, w_dst, model.path_bgr_src, model.path_bgr_dst, batch_size)\n",
    "        errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n",
    "        for k in ['ttl', 'adv', 'recon', 'edge', 'pl']:\n",
    "            errGAs[k] = 0\n",
    "            errGBs[k] = 0\n",
    "            pass\n",
    "\n",
    "        # Save models\n",
    "        model.save_weights(path=models_dir)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random results\n",
    "\n",
    "w_src, t_src, _ = train_batch_src.get_next_batch()\n",
    "w_dst, t_dst, _ = train_batch_dst.get_next_batch()\n",
    "print(\"Преобразованные (замаскированные) результаты:\")\n",
    "showG(t_src, t_dst, model.path_src, model.path_dst, batch_size)\n",
    "print(\"Маски:\")\n",
    "showG_mask(t_src, t_dst, model.path_mask_src, model.path_mask_dst, batch_size)\n",
    "print(\"Результаты реконструкции:\")\n",
    "showG(w_src, w_dst, model.path_bgr_src, model.path_bgr_dst, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='tf'></a>\n",
    "# Преобразование Одного Изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from detector.face_detector import MTCNNFaceDetector\n",
    "from converter.landmarks_alignment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn_weights_dir = \"./mtcnn_weights/\"\n",
    "fd = MTCNNFaceDetector(sess=K.get_session(), model_path=mtcnn_weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converter.face_transformer import FaceTransformer\n",
    "\n",
    "ftrans = FaceTransformer()\n",
    "ftrans.set_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input image\n",
    "input_img = plt.imread(\"./TEST_IMAGE.jpg\")[..., :3]\n",
    "\n",
    "if input_img.dtype == np.float32:\n",
    "    print(\"input_img имеет тип dtype np.float32. Масштабируем его до uint8.\")\n",
    "    input_img = (input_img * 255).astype(np.uint8)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display input image\n",
    "plt.imshow(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detected face\n",
    "face, lms = fd.detect_face(input_img)\n",
    "aligned_det_face_im = None\n",
    "(tar_landmarks, src_landmarks) = (None, None)\n",
    "x0, y1, x1, y0 = (0, 0, 0, 0)\n",
    "if len(face) == 1:\n",
    "    x0, y1, x1, y0, _ = face[0]\n",
    "    det_face_im = input_img[int(x0):int(x1), int(y0):int(y1), :]\n",
    "    try:\n",
    "        src_landmarks = get_src_landmarks(x0, x1, y0, y1, lms)\n",
    "        tar_landmarks = get_tar_landmarks(det_face_im)\n",
    "        aligned_det_face_im = landmarks_match_mtcnn(det_face_im, src_landmarks, tar_landmarks)\n",
    "    except:\n",
    "        print(\"Во время выравнивания лиц произошла ошибка.\")\n",
    "        aligned_det_face_im = det_face_im\n",
    "elif len(face) == 0:\n",
    "    raise ValueError(\"Ошибка: лицо не обнаружено.\")\n",
    "elif len(face) > 1:\n",
    "    print(face)\n",
    "    raise ValueError(\"Ошибка: обнаружено несколько лиц\")\n",
    "\n",
    "if aligned_det_face_im:\n",
    "    plt.imshow(aligned_det_face_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform detected face\n",
    "result_img, result_rgb, result_mask = ftrans.transform(\n",
    "    aligned_det_face_im,\n",
    "    direction=\"AtoB\",\n",
    "    roi_coverage=0.93,\n",
    "    color_correction=\"adain_xyz\",\n",
    "    IMAGE_SHAPE=(RESOLUTION, RESOLUTION, 3)\n",
    ")\n",
    "try:\n",
    "    result_img = landmarks_match_mtcnn(result_img, tar_landmarks, src_landmarks)\n",
    "    result_rgb = landmarks_match_mtcnn(result_rgb, tar_landmarks, src_landmarks)\n",
    "    result_mask = landmarks_match_mtcnn(result_mask, tar_landmarks, src_landmarks)\n",
    "except:\n",
    "    print(\"Во время выравнивания лица произошла ошибка.\")\n",
    "    pass\n",
    "\n",
    "result_input_img = input_img.copy()\n",
    "result_input_img[int(x0):int(x1), int(y0):int(y1), :] = (\n",
    "        result_mask.astype(np.float32) / 255 * result_rgb +\n",
    "        (1 - result_mask.astype(np.float32) / 255) * result_input_img[\n",
    "                                                     int(x0):int(x1),\n",
    "                                                     int(y0):int(y1), :]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show result face\n",
    "plt.imshow(result_input_img[int(x0):int(x1), int(y0):int(y1), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show transformed image before masking\n",
    "plt.imshow(result_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show alpha mask\n",
    "plt.imshow(result_mask[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display interpolations before/after transformation\n",
    "def interpolate_imgs(im1, im2):\n",
    "    im1, im2 = map(np.float32, [im1, im2])\n",
    "    out = [ratio * im1 + (1 - ratio) * im2 for ratio in np.linspace(1, 0, 5)]\n",
    "    out = map(np.uint8, out)\n",
    "    return out\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(np.hstack(interpolate_imgs(input_img, result_input_img)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}