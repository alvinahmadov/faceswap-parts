{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiOo3478pJg9"
   },
   "source": [
    "# Приготовления\n",
    "\n",
    "Этот colab notebook является минимальной демонстрацией для Faceswap GAN.\n",
    "Поскольку colab допускает максимальное время работы 12 часов, мы будем\n",
    "обучать только облегченную модель в этом notebook.\n",
    "\n",
    "**Цель этой notebook - не обучить модель, которая дает высококачественные результаты, а дать краткий обзор того, как работает faceswap-GAN, а также для замены частей лица.**\n",
    "\n",
    "Порядок работы faceswap-GAN описан ниже:\n",
    "\n",
    "  1. Загрузите два видео для обучения;\n",
    "  2. Примените извлечение лица (предварительную обработку) к двум загруженным видео;\n",
    "  3. Тренируйте легкую модель для Faceswap GAN. (~10-12 ч.)\n",
    "  4. Примените преобразование видео к загруженным видео."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf8Wvh5Wrm3V"
   },
   "source": [
    "# Шаг 1: Установите тип среды выполнения на Python 3/GPU\n",
    "Установите ноутбук colab в экземпляр GPU с помощью:\n",
    "**runtime -> change runtime type -> Python3 and GPU**\n",
    "\n",
    "В следующих ячейках будет отображена системная информация текущего экземпляра.\n",
    "Запустите ячейки и проверьте, использует ли он python > = 3.6 и имеет ли устройство GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eliuDt0QzYG4"
   },
   "source": [
    "Для выполнения кода в colab рекомендуется подключить Google Drive (или Google Storage) для перманентного хранения получаемых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsRLACx0VLUG",
    "outputId": "4571726e-ab42-4561-d7f6-144a8ab6b869"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3odWIKOYNTG_"
   },
   "source": [
    "Создаем директорию для данных на Google Drive или bucket в Google Storage (не реализовано)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzIBmLv4Zsrl"
   },
   "source": [
    "Создаем директорию для перманентного сохранения полученных данных в Google Drive или bucket в Google Storage (не реализовано). Colab возвращает ВМ в состояние по умолчанию, если сеанс не активен. Код ниже должен выполняться **единожды**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gS8mW4roMhq"
   },
   "outputs": [],
   "source": [
    "!mkdir -p /content/drive/MyDrive/faceswap_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zQhhPfKrmQl",
    "outputId": "4a96cdae-689a-4db6-a059-52a6c7a2a07e"
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtQyQPA2MGJv"
   },
   "source": [
    "Устанавливаем зависимости:\n",
    "\n",
    "```\n",
    "tensorflow-gpu==1.15.5\n",
    "h5py==2.10.0\n",
    "opencv-python\n",
    "keras==2.1.5\n",
    "Keras-Applications\n",
    "Keras-Preprocessing\n",
    "imageio==2.4.1\n",
    "matplotlib\n",
    "requests\n",
    "moviepy\n",
    "Pillow\n",
    "PyYAML\n",
    "IPython\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeOr9fdqP6c5"
   },
   "outputs": [],
   "source": [
    "# restart the runtime after installation completes\n",
    "!pip install tensorflow==1.15.5 h5py==2.10.0 keras==2.1.5 imageio==2.4.1 moviepy==0.2.3.5 opencv-python keras_applications matplotlib requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chIjksUYn0Rn"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOsTN_gjzonZ"
   },
   "source": [
    "# Шаг 2: Клонируйте репозиторий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4VioT5YpJQB",
    "outputId": "9349d873-24ae-4755-9b4a-b1051a54a0af"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/alvinahmadov/faceswap-parts.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_4C8o3y0DFD",
    "outputId": "4c15b0d7-63a2-49be-862a-65f04be1c7b2"
   },
   "outputs": [],
   "source": [
    "!git stash\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2osRp-G-u0n",
    "outputId": "9ef3c99b-1938-40f1-9181-8afca388b533"
   },
   "outputs": [],
   "source": [
    "%cd \"faceswap-parts\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K0wsds0OslRc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(f\"Tensorflow version {tf.version.VERSION}\")\n",
    "\n",
    "device_lib.list_local_devices()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ0HH6VUpJHW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Шаг 3: Загрузите видеоролики обучения\n",
    "\n",
    "Пользователь должен загрузить два видео: **source video** и **target video**.\n",
    "Модель **преобразует исходное лицо в целевое по умолчанию.**\n",
    "\n",
    "  - Видео, для лучшего результата должен **содержать только одного человека**.\n",
    "  - Ограничений по длине видео нет, но чем оно длиннее, тем больше времени потребуется\n",
    "на предварительную обработку/преобразование видео, что может привести к увеличению времени\n",
    "выполнения до 12 часов. (**Рекомендуемая продолжительность видео: 30 секунд ~ 2 минуты.**)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e1AUfdGGXdVG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "try:\n",
    "    # noinspection PyUnresolvedReferences,PyPackageRequirements\n",
    "    from google.colab import files\n",
    "except ImportError:\n",
    "    print(\"This notebook can be run only in google colab\")\n",
    "    pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rwNkccAXjdG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Можно использовать тестовые видео (выбирать только один способ)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hz84WNN9XXsa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fn_source_video=\"samples/source.mp4\"\n",
    "fn_target_video=\"samples/target.mp4\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "thlzp88qpJJk",
    "outputId": "de143925-d293-45c9-cd1a-3a92d44617c2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Или можно загрузить свои файлы для обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyKu2hcCpJKu"
   },
   "outputs": [],
   "source": [
    "# Upload source video\n",
    "source_video = files.upload()\n",
    "\n",
    "for fn_source_video, _ in source_video.items():\n",
    "    print(fn_source_video)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PS25Uu9kxDwo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Upload target video\n",
    "target_video = files.upload()\n",
    "\n",
    "for fn_target_video, _ in target_video.items():\n",
    "    print(fn_target_video)\n",
    "    pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY3qysVq0p2P",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Шаг 5: Все готово.\n",
    "\n",
    "**Нажмите Ctrl + F10 (или runtime -> run after)**, чтобы запустить процесс. Для завершения\n",
    "тренировки потребуется 10 ~ 12 часов. Результирующее видео можно загрузить, запустив\n",
    "последнюю ячейку:\n",
    "  ```shell\n",
    "  files.download(\"OUTPUT_VIDEO.mp4\")\n",
    "  ```\n",
    "Обратите внимание, что **эту страницу не следует закрывать или обновлять во время работы**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ym0EsJk9pJRw",
    "outputId": "f792fd0b-e8cc-4da9-d06d-098ff2800ecd"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import imageio\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otuzS3Di0gvz"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from detector import MTCNNFaceDetector\n",
    "\n",
    "from preprocess import preprocess_video"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x39o2BbTYKDk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fd = MTCNNFaceDetector(sess=K.get_session(), model_path=\"./mtcnn_weights/\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfJ4u3CqYO22",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Устанавливаем константы для сохранения"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "myxLSD4OtiY6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "TRAIN_DIR=\"/content/drive/MyDrive/faceswap_train\"\n",
    "\n",
    "# Path to saved model weights\n",
    "MODELS_DIR=f\"{TRAIN_DIR}/models\"\n",
    "VGGFACE_WEIGHT_FILE=f\"{TRAIN_DIR}/models/rcmalli_vggface_tf_notop_resnet50.h5\"\n",
    "\n",
    "# Path to training images\n",
    "SAVE_PATH_SOURCE=f\"{TRAIN_DIR}/face_src\"\n",
    "SAVE_PATH_TARGET=f\"{TRAIN_DIR}/face_dst\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kt5FVEt11B2K",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Создаем директории для сохранения извлеченных данных, а также для моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wxu_73upa48L"
   },
   "outputs": [],
   "source": [
    "from utils import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO11aRsZ0gyK"
   },
   "outputs": [],
   "source": [
    "# Create image extraction dirs\n",
    "for spath in [SAVE_PATH_SOURCE, SAVE_PATH_TARGET]:\n",
    "  makedirs([f\"{spath}/rgb\", f\"{spath}/binary_mask\"])\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wfCp5Mp-txf9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "save_interval = 5 # perform face detection every {save_interval} frames\n",
    "\n",
    "preprocess_video(fn_source_video, fd, save_interval, f\"{SAVE_PATH_SOURCE}/\")\n",
    "preprocess_video(fn_target_video, fd, save_interval, f\"{SAVE_PATH_TARGET}/\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIb9TSMz0g0g",
    "outputId": "729f5d52-01d6-4e39-e0db-b6c0b35fa817",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Получаем количество извлеченных данных"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O9L5UW8U3AaQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import glob\n",
    "face_src_glob_len=str(len(glob.glob(f\"{SAVE_PATH_SOURCE}/rgb/*.*\")))\n",
    "face_dst_glob_len=str(len(glob.glob(f\"{SAVE_PATH_TARGET}/rgb/*.*\")))\n",
    "\n",
    "print(f\"{face_src_glob_len} лиц извлечено из исходного видео: {fn_source_video}.\")\n",
    "print(f\"{face_dst_glob_len} лиц извлечено из целевого видео: {fn_target_video}.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtyeXpEc2lDO"
   },
   "source": [
    "## Следующие ячейки взяты из [faceswap_train_test.ipynb](https://github.com/alvinahmadov/faceswap-parts/blob/main/faceswap_train_test.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtENXluJ0g2I",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Импортируйте пакеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFAokeU12Vff"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TbN1b6-O-u0t",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt9r0GI6-u0u",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Установите максимальное количество итераций обучения\n",
    "Для 25000 итераций по умолчанию требуется ~10 часов обучения.\n",
    "\n",
    "**`Итерации >= 27k могут превышать предельное время выполнения;`**\n",
    "\n",
    "**`Итерации < 18k могут привести к плохо обученной модели.`**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EJ1miHVk2ns7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "TOTAL_ITERS = 21300 # total number of iterations\n",
    "DISPLAY_ITERS = 300 # each n iters display results"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjrPsIbZ2ViU",
    "outputId": "dabc08f8-4409-4176-a130-8c42a1ac71ff",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Конфигурация"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bSrt2h0K3so3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "K.set_learning_phase(1)\n",
    "# Number of CPU cores\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "# Input/Output resolution\n",
    "RESOLUTION = 64  # 64x64, 128x128, 256x256\n",
    "assert (RESOLUTION % 64) == 0, \"RESOLUTION should be 64, 128, or 256.\"\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# Where to save checkpoints\n",
    "checkpoint_file=f\"{MODELS_DIR}/checkpoint\"\n",
    "\n",
    "# Use motion blur (data augmentation)\n",
    "# set True if training data contains images extracted from videos\n",
    "use_da_motion_blur = False\n",
    "\n",
    "# Use eye-aware training\n",
    "# require images generated from prep_binary_masks.ipynb\n",
    "use_bm_eyes = True\n",
    "\n",
    "# Probability of random color matching (data augmentation)\n",
    "prob_random_color_match = 0.5\n",
    "\n",
    "da_config = {\n",
    "    \"prob_random_color_match\": prob_random_color_match,\n",
    "    \"use_da_motion_blur\": use_da_motion_blur,\n",
    "    \"use_bm_eyes\": use_bm_eyes\n",
    "}\n",
    "\n",
    "# Path to training images\n",
    "img_dir_src = f\"{SAVE_PATH_SOURCE}/rgb\" # source face\n",
    "img_dir_dst = f\"{SAVE_PATH_TARGET}/rgb\" # target face\n",
    "img_dir_src_bm_eyes = f\"{SAVE_PATH_SOURCE}/binary_mask\"\n",
    "img_dir_dst_bm_eyes = f\"{SAVE_PATH_TARGET}/binary_mask\"\n",
    "\n",
    "\n",
    "# Architecture configuration\n",
    "arch_config = {\n",
    "    \"IMAGE_SHAPE\": (RESOLUTION, RESOLUTION, 3),\n",
    "    \"use_self_attn\": True,\n",
    "    \"norm\": \"hybrid\",\n",
    "    \"model_capacity\": \"lite\"\n",
    "}\n",
    "\n",
    "# Loss function weights configuration\n",
    "loss_weights = {\n",
    "    \"w_D\": 0.1,\n",
    "    \"w_recon\": 1.,\n",
    "    \"w_edge\": 0.1,\n",
    "    \"w_eyes\": 30.,\n",
    "    \"w_pl\": (0.01, 0.1, 0.3, 0.1)\n",
    "}\n",
    "\n",
    "# Init. loss config.\n",
    "loss_config = {\n",
    "    \"gan_training\": \"mixup_LSGAN\",\n",
    "    \"use_PL\": False,\n",
    "    \"PL_before_activ\": True,\n",
    "    \"use_mask_hinge_loss\": False,\n",
    "    \"m_mask\": 0.,\n",
    "    \"lr_factor\": 1.,\n",
    "    \"use_cyclic_loss\": False\n",
    "}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5o2dEVW92Vms",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Постройте модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yiNsc3N_2VhU"
   },
   "outputs": [],
   "source": [
    "from nn.faceswap_model import FaceswapModel\n",
    "from loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W7i4WpimbiFS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model = FaceswapModel(**arch_config)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PK0DAxeu-u0z",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Скачиваем модель из `rcmalli_vggface_tf_notop_resnet50` и сохраняем в директории моделей `.../faceswap_train/models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvVr2TqI3jd9"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5 -P /content/drive/MyDrive/faceswap_train/models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GexJ-i7c3vz2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from nn.vggface import RESNET50\n",
    "\n",
    "vggface = RESNET50(include_top=False, weights=None, input_shape=(224, 224, 3))\n",
    "vggface.load_weights(VGGFACE_WEIGHT_FILE, by_name=True)\n",
    "\n",
    "model.build_pl_model(vggface_model=vggface, before_activ=loss_config[\"PL_before_activ\"])\n",
    "model.build_train_functions(loss_weights=loss_weights, **loss_config)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoCnWQiR3jgd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Начните тренировку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjkSygNT3jjB",
    "outputId": "d35137d9-fe8c-40ee-aee6-f9a372811e57"
   },
   "outputs": [],
   "source": [
    "# Create ./models directory\n",
    "makedirs([MODELS_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KzKahMU3jlX"
   },
   "outputs": [],
   "source": [
    "# Get file names\n",
    "train_src = glob.glob(f\"{img_dir_src}/*.*\")\n",
    "train_dst = glob.glob(f\"{img_dir_dst}/*.*\")\n",
    "\n",
    "train_src_n_dst = train_src + train_dst\n",
    "\n",
    "assert len(train_src), f\"Изображение не найдено в {img_dir_src}\"\n",
    "assert len(train_dst), f\"Изображение не найдено в {img_dir_dst}\"\n",
    "print(f\"Количество изображений в папке A: {str(len(train_src))}\")\n",
    "print(f\"Количество изображений в папке B: {str(len(train_dst))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создаем класс для записи/чтения контрольных точек для непрерывного обучения."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5fwrKth3jqO"
   },
   "outputs": [],
   "source": [
    "from utils import CheckPoint, save_image, save_loss_data, showG, showG_mask"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def show_loss_config(loss_conf):\n",
    "    for config, value in loss_conf.items():\n",
    "        print(f\"{config} = {value}\")\n",
    "        pass\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Показываем события для этапов обучения"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def show_conditions(gen_iterations, cond=None):\n",
    "    info_msg = \"Выполняется условие \"\n",
    "    cond_msg0 = f\"0: gen_iterations % display_iters == {(gen_iterations % DISPLAY_ITERS) == 0}\"\n",
    "    cond_msg1 = f\"1: gen_iterations == {(TOTAL_ITERS // 5 - DISPLAY_ITERS // 2)}\"\n",
    "    cond_msg2 = f\"2: gen_iterations == {(TOTAL_ITERS // 5 + TOTAL_ITERS // 10 - DISPLAY_ITERS // 2)}\"\n",
    "    cond_msg3 = f\"3: gen_iterations == {(2 * TOTAL_ITERS // 5 - DISPLAY_ITERS // 2)}\"\n",
    "    cond_msg4 = f\"4: gen_iterations == {(TOTAL_ITERS // 2 - DISPLAY_ITERS // 2)}\"\n",
    "    cond_msg5 = f\"5: gen_iterations == {(2 * TOTAL_ITERS // 3 - DISPLAY_ITERS // 2)}\"\n",
    "    cond_msg6 = f\"6: gen_iterations == {(8 * TOTAL_ITERS // 10 - DISPLAY_ITERS // 2)}\"\n",
    "    cond_msg7 = f\"7: gen_iterations == {(9 * TOTAL_ITERS // 10 - DISPLAY_ITERS // 2)}\"\n",
    "\n",
    "    if cond is None:\n",
    "        print(f\"Условия:\\n\\t{cond_msg1}\\n\\t{cond_msg2}\\n\\t{cond_msg3}\\n\\t{cond_msg4}\"\n",
    "              f\"\\n\\t{cond_msg5}\\n\\t{cond_msg6}\\n\\t{cond_msg7}\\n\\t{cond_msg0}\\n\\n\")\n",
    "        pass\n",
    "    elif cond == 0:\n",
    "        print(info_msg + cond_msg0)\n",
    "        pass\n",
    "    elif cond == 1:\n",
    "        print(info_msg + cond_msg1)\n",
    "        pass\n",
    "    elif cond == 2:\n",
    "        print(info_msg + cond_msg2)\n",
    "        pass\n",
    "    elif cond == 3:\n",
    "        print(info_msg + cond_msg3)\n",
    "        pass\n",
    "    elif cond == 4:\n",
    "        print(info_msg + cond_msg4)\n",
    "        pass\n",
    "    elif cond == 5:\n",
    "        print(info_msg + cond_msg5)\n",
    "        pass\n",
    "    elif cond == 6:\n",
    "        print(info_msg + cond_msg6)\n",
    "        pass\n",
    "    elif cond == 7:\n",
    "        print(info_msg + cond_msg7)\n",
    "        pass\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU0t3mhQOImh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Сбрасываем сессию"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def reset_session(spath):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spath : str\n",
    "     Save path\n",
    "    \"\"\"\n",
    "    global model, vggface\n",
    "    global train_batch_src, train_batch_dst\n",
    "    model.save_weights(path=spath)\n",
    "    del model\n",
    "    del vggface\n",
    "    del train_batch_src\n",
    "    del train_batch_dst\n",
    "    K.clear_session()\n",
    "    model = FaceswapModel(**arch_config)\n",
    "    model.load_weights(path=spath)\n",
    "    vggface = RESNET50(include_top=False, weights=None, input_shape=(224, 224, 3))\n",
    "    vggface.load_weights(VGGFACE_WEIGHT_FILE)\n",
    "    model.build_pl_model(vggface_model=vggface, before_activ=loss_config[\"PL_before_activ\"])\n",
    "    train_batch_src = DataLoader(filenames=train_src, all_filenames=train_src_n_dst,\n",
    "                                 batch_size=batch_size, dir_bm_eyes=img_dir_src_bm_eyes,\n",
    "                                 resolution=RESOLUTION, num_cpus=num_cpus, session=K.get_session(),\n",
    "                                 **da_config)\n",
    "    train_batch_dst = DataLoader(filenames=train_dst, all_filenames=train_src_n_dst,\n",
    "                                 batch_size=batch_size, dir_bm_eyes=img_dir_dst_bm_eyes,\n",
    "                                 resolution=RESOLUTION, num_cpus=num_cpus, session=K.get_session(),\n",
    "                                 **da_config)\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pMDOy8tpOViQ",
    "outputId": "f6a28a84-47ad-4b62-9faa-c401846b5d58"
   },
   "outputs": [],
   "source": [
    "TRAIN_RESULTS_DIR=f\"{TRAIN_DIR}/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x58lrjkw6iQM"
   },
   "source": [
    "\n",
    "Определяем функцию обучения.\n",
    "\n",
    "Примечание: При использовании обучения на tensorflow-cpu мин. время выполнения блока кода составляло ~ 15 сек.\n",
    "При ипользовании tensorflow-gpu то же время составило ~ 1 сек.\n",
    "\n",
    "Для оптимальных результатов (как по времени, так и по качеству) рекомендуется значение\n",
    "`TOTAL_ITERS == 18 000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOi2ZsSa4vf4"
   },
   "outputs": [],
   "source": [
    "def train(checkpoint):\n",
    "    clear_output()\n",
    "    # Start training\n",
    "    t0 = time.time()\n",
    "\n",
    "    model_dir=f\"{MODELS_DIR}\"\n",
    "\n",
    "    # This try/except is meant to resume training if we disconnected from Colab\n",
    "\n",
    "    try:\n",
    "      gen_iterations\n",
    "      print(f\"Возобновить обучение c {gen_iterations} итерации.\")\n",
    "      checkpoint.save(gen_iterations, t0)\n",
    "    except:\n",
    "      gen_iterations = checkpoint.load().iter\n",
    "      print(f\"Возобновить обучение c {gen_iterations} итерации.\")\n",
    "      pass\n",
    "\n",
    "    def show_cond(cond=None):\n",
    "        show_conditions(gen_iterations, cond)\n",
    "\n",
    "    errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n",
    "    errGAs = {}\n",
    "    errGBs = {}\n",
    "\n",
    "    for k in ['ttl', 'adv', 'recon', 'edge', 'pl']:\n",
    "        errGAs[k] = 0\n",
    "        errGBs[k] = 0\n",
    "        pass\n",
    "\n",
    "    global TOTAL_ITERS\n",
    "    global train_batch_src, train_batch_dst\n",
    "\n",
    "    train_batch_src = DataLoader(train_src, train_src_n_dst, batch_size,\n",
    "                                 dir_bm_eyes=img_dir_src_bm_eyes, resolution=RESOLUTION,\n",
    "                                 num_cpus=num_cpus, session=K.get_session(), **da_config)\n",
    "\n",
    "    train_batch_dst = DataLoader(train_dst, train_src_n_dst, batch_size,\n",
    "                                 dir_bm_eyes=img_dir_dst_bm_eyes, resolution=RESOLUTION,\n",
    "                                 num_cpus=num_cpus, session=K.get_session(), **da_config)\n",
    "\n",
    "    show_cond()\n",
    "    save_path = \"\"\n",
    "    while gen_iterations <= TOTAL_ITERS:\n",
    "        # Loss function automation\n",
    "        if (gen_iterations + 1) % DISPLAY_ITERS == 0:\n",
    "            print(f\"Выполняется итерация {gen_iterations}/{TOTAL_ITERS}\")\n",
    "        exec_time = time.time()\n",
    "\n",
    "        # condition1\n",
    "        if gen_iterations == (TOTAL_ITERS // 5 - DISPLAY_ITERS // 2):\n",
    "            show_cond(1)\n",
    "            loss_config['use_PL'] = True\n",
    "            loss_config['use_mask_hinge_loss'] = False\n",
    "            loss_config['m_mask'] = 0.0\n",
    "            reset_session(model_dir)\n",
    "            print(\"Конструкция новых функций потерь...\")\n",
    "            show_loss_config(loss_config)\n",
    "            model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "            t1 = time.time() - exec_time\n",
    "            print(\"Условие %i выполнено за %.2f сек.\" % (1, t1))\n",
    "            pass\n",
    "        # condition2\n",
    "        elif gen_iterations == (TOTAL_ITERS // 5 + TOTAL_ITERS // 10 - DISPLAY_ITERS // 2):\n",
    "            show_cond(2)\n",
    "            loss_config['use_PL'] = True\n",
    "            loss_config['use_mask_hinge_loss'] = True\n",
    "            loss_config['m_mask'] = 0.5\n",
    "            reset_session(model_dir)\n",
    "            print(\"Конструкция новых функций потерь...\")\n",
    "            show_loss_config(loss_config)\n",
    "            model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "            t1 = time.time() - exec_time\n",
    "            print(\"Условие %i выполнено за %.2f сек.\" % (2, t1))\n",
    "            pass\n",
    "        # condition3\n",
    "        elif gen_iterations == (2 * TOTAL_ITERS // 5 - DISPLAY_ITERS // 2):\n",
    "            show_cond(3)\n",
    "            loss_config['use_PL'] = True\n",
    "            loss_config['use_mask_hinge_loss'] = True\n",
    "            loss_config['m_mask'] = 0.2\n",
    "            reset_session(model_dir)\n",
    "            print(\"Конструкция новых функций потерь...\")\n",
    "            show_loss_config(loss_config)\n",
    "            model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "            t1 = time.time() - exec_time\n",
    "            print(\"Условие %i выполнено за %.2f сек.\" % (3, t1))\n",
    "            pass\n",
    "        # condition4\n",
    "        elif gen_iterations == (TOTAL_ITERS // 2 - DISPLAY_ITERS // 2):\n",
    "            show_cond(4)\n",
    "            loss_config['use_PL'] = True\n",
    "            loss_config['use_mask_hinge_loss'] = True\n",
    "            loss_config['m_mask'] = 0.4\n",
    "            loss_config['lr_factor'] = 0.3\n",
    "            reset_session(model_dir)\n",
    "            print(\"Конструкция новых функций потерь...\")\n",
    "            show_loss_config(loss_config)\n",
    "            model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "            t1 = time.time() - exec_time\n",
    "            print(\"Условие %i выполнено за %.2f сек.\" % (4, t1))\n",
    "            pass\n",
    "        # condition5\n",
    "        elif gen_iterations == (2 * TOTAL_ITERS // 3 - DISPLAY_ITERS // 2):\n",
    "            show_cond(5)\n",
    "            model.decoder_src.load_weights(f\"{model_dir}/decoder_B.h5\")  # swap decoders\n",
    "            model.decoder_dst.load_weights(f\"{model_dir}/decoder_A.h5\")  # swap decoders\n",
    "            loss_config['use_PL'] = True\n",
    "            loss_config['use_mask_hinge_loss'] = True\n",
    "            loss_config['m_mask'] = 0.5\n",
    "            loss_config['lr_factor'] = 1\n",
    "            reset_session(model_dir)\n",
    "            print(\"Конструкция новых функций потерь...\")\n",
    "            show_loss_config(loss_config)\n",
    "            model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "            t1 = time.time() - exec_time\n",
    "            print(\"Условие %i выполнено за %.2f сек.\" % (5, t1))\n",
    "            pass\n",
    "        # condition6\n",
    "        elif gen_iterations == (8 * TOTAL_ITERS // 10 - DISPLAY_ITERS // 2):\n",
    "            show_cond(6)\n",
    "            loss_config['use_PL'] = True\n",
    "            loss_config['use_mask_hinge_loss'] = True\n",
    "            loss_config['m_mask'] = 0.1\n",
    "            loss_config['lr_factor'] = 0.3\n",
    "            reset_session(model_dir)\n",
    "            print(\"Конструкция новых функций потерь...\")\n",
    "            show_loss_config(loss_config)\n",
    "            model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "            t1 = time.time() - exec_time\n",
    "            print(\"Условие %i выполнено за %.2f сек.\" % (6, t1))\n",
    "            pass\n",
    "        # condition7\n",
    "        elif gen_iterations == (9 * TOTAL_ITERS // 10 - DISPLAY_ITERS // 2):\n",
    "            show_cond(7)\n",
    "            loss_config['use_PL'] = True\n",
    "            loss_config['use_mask_hinge_loss'] = False\n",
    "            loss_config['m_mask'] = 0.0\n",
    "            loss_config['lr_factor'] = 0.1\n",
    "            reset_session(model_dir)\n",
    "            print(\"Конструкция новых функций потерь...\")\n",
    "            show_loss_config(loss_config)\n",
    "            model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "            t1 = time.time() - exec_time\n",
    "            print(\"Условие %i выполнено за %.2f сек.\" % (7, t1))\n",
    "            pass\n",
    "\n",
    "        # Train dicriminators for one batch\n",
    "        data_src = train_batch_src.get_next_batch()\n",
    "        data_dst = train_batch_dst.get_next_batch()\n",
    "        errDA, errDB = model.train_one_batch_disc(data_src, data_dst)\n",
    "        errDA_sum += errDA[0]\n",
    "        errDB_sum += errDB[0]\n",
    "\n",
    "        # Train generators for one batch\n",
    "        data_src = train_batch_src.get_next_batch()\n",
    "        data_dst = train_batch_dst.get_next_batch()\n",
    "        errGA, errGB = model.train_one_batch_gen(data_src, data_dst)\n",
    "        errGA_sum += errGA[0]\n",
    "        errGB_sum += errGB[0]\n",
    "        for i, k in enumerate(['ttl', 'adv', 'recon', 'edge', 'pl']):\n",
    "            errGAs[k] += errGA[i]\n",
    "            errGBs[k] += errGB[i]\n",
    "            pass\n",
    "\n",
    "        gen_iterations += 1\n",
    "\n",
    "        # Visualization\n",
    "        if gen_iterations % DISPLAY_ITERS == 0:\n",
    "            show_cond(0)\n",
    "\n",
    "            # Display loss information\n",
    "            show_loss_config(loss_config)\n",
    "\n",
    "            train_info=\"[iter %d] time: %f\\nLoss_DA: %f Loss_DB: %f\\nLoss_GA: %f Loss_GB: %f\" % (\n",
    "                gen_iterations, time.time() - t0, errDA_sum / DISPLAY_ITERS, errDB_sum / DISPLAY_ITERS,\n",
    "                errGA_sum / DISPLAY_ITERS, errGB_sum / DISPLAY_ITERS\n",
    "            )\n",
    "            train_info=f\"\\n{train_info}\\n###################################\"\n",
    "\n",
    "            adv_loss_info = f\"[Adversarial loss]\\nGA: {errGAs['adv'] / DISPLAY_ITERS:.4f} GB: {errGBs['adv'] / DISPLAY_ITERS:.4f}\"\n",
    "            rec_loss_info = f\"[Reconstruction loss]\\nGA: {errGAs['recon'] / DISPLAY_ITERS:.4f} GB: {errGBs['recon'] / DISPLAY_ITERS:.4f}\"\n",
    "            edg_loss_info = f\"[Edge loss]\\nGA: {errGAs['edge'] / DISPLAY_ITERS:.4f} GB: {errGBs['edge'] / DISPLAY_ITERS:.4f}\"\n",
    "            prc_loss_info = \"\"\n",
    "\n",
    "            try:\n",
    "                prc_loss_info = f\"[Perceptual loss]\\nGA: {errGAs['pl'][0] / DISPLAY_ITERS:.4f} GB: {errGBs['pl'][0] / DISPLAY_ITERS:.4f}\"\n",
    "            except:\n",
    "                prc_loss_info = f\"[Perceptual loss]\\nGA: {errGAs['pl'] / DISPLAY_ITERS:.4f} GB: {errGBs['pl'] / DISPLAY_ITERS:.4f}\"\n",
    "                pass\n",
    "\n",
    "            # print(train_info)\n",
    "            # print(\"Детали потерь генератора:\")\n",
    "            # print(adv_loss_info)\n",
    "            # print(rec_loss_info)\n",
    "            # print(edg_loss_info)\n",
    "\n",
    "            # if loss_config['use_PL']:\n",
    "            #     print(prc_loss_info)\n",
    "            #     pass\n",
    "\n",
    "            loss_info = f\"{train_info}\\n{adv_loss_info}\\n{rec_loss_info}\\n{edg_loss_info}\\n{prc_loss_info}\"\n",
    "\n",
    "            save_path = f\"{TRAIN_RESULTS_DIR}/{gen_iterations}\"\n",
    "            makedirs([save_path])\n",
    "            save_loss_data(save_path, loss_info)\n",
    "\n",
    "            w_src, t_src, _ = train_batch_src.get_next_batch()\n",
    "            w_dst, t_dst, _ = train_batch_dst.get_next_batch()\n",
    "\n",
    "            # Save images\n",
    "            print(\"Преобразованные результаты:\")\n",
    "            save_image(t_src, t_dst, model.path_src, model.path_dst, batch_size,\n",
    "                       im_save_path=save_path, filename=\"preproc.png\")\n",
    "\n",
    "            showG(t_src, t_dst, model.path_src, model.path_dst, batch_size)\n",
    "            print(\"Маски:\")\n",
    "            save_image(t_src, t_dst, model.path_mask_src, model.path_mask_dst,\n",
    "                       batch_size, im_save_path=save_path, filename=\"bm.png\", is_mask=True)\n",
    "            showG_mask(t_src, t_dst, model.path_mask_src, model.path_mask_dst, batch_size)\n",
    "            print(\"Результаты реконструкции:\")\n",
    "            save_image(w_src, w_dst, model.path_bgr_src, model.path_bgr_dst, batch_size,\n",
    "                       im_save_path=save_path, filename=\"recon.png\")\n",
    "            showG(w_src, w_dst, model.path_bgr_src, model.path_bgr_dst, batch_size)\n",
    "            errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n",
    "            for k in ['ttl', 'adv', 'recon', 'edge', 'pl']:\n",
    "                errGAs[k] = 0\n",
    "                errGBs[k] = 0\n",
    "                pass\n",
    "\n",
    "            # Save models\n",
    "            model.save_weights(path=model_dir)\n",
    "\n",
    "            t1 = time.time() - exec_time\n",
    "            print(\"Сохранение модели выполнено за %.2f сек.\" % (t1))\n",
    "            pass\n",
    "\n",
    "        t1 = time.time() - exec_time\n",
    "        checkpoint.save(gen_iterations, t1)\n",
    "        print(\"Выполнение блока кода завершено за %.2f сек. (осталось ~%.2f сек.)\\n\" % (t1, (TOTAL_ITERS - gen_iterations)*t1))\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSjrBGL_-u05",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Начинаем обучение.\n",
    "\n",
    "Благодаря системе записи/чтения состояний обучения, а также сохранения результатов, операцию\n",
    "обучения можно выполнять прерывно, даже если произошло исключение или остановка процесса.\n",
    "При каждом завершении обучения для текущего `TOTAL_ITERS` итераций, можно улучшить результат\n",
    "повышая значение `TOTAL_ITERS`, но при условии, если **`TOTAL_ITERS` % `DISPLAY_ITERS` == 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4uUub3A4vi7"
   },
   "outputs": [],
   "source": [
    "checkpoint = CheckPoint(checkpoint_file)\n",
    "\n",
    "try:\n",
    "    train(checkpoint)\n",
    "except:\n",
    "    checkpoint.save(checkpoint.load().iter + 1)\n",
    "    pass\n",
    "\n",
    "print(\"Training finished at checkpoint \" + str(checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxwjrVoc4vmQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Конвертация видео\n",
    "[faceswap_video_conversion.ipynb](https://github.com/alvinahmadov/faceswap-parts/blob/main/colab/faceswap_video_conversion.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyuELtb94vpr"
   },
   "outputs": [],
   "source": [
    "from converter import Converter\n",
    "from converter.config import ConverterConfig, TransformDirection, ImageOutputType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sem7RMzm4vr6"
   },
   "outputs": [],
   "source": [
    "global model, vggface\n",
    "global train_batch_src, train_batch_dst\n",
    "try:\n",
    "  del model\n",
    "  del vggface\n",
    "  del train_batch_src\n",
    "  del train_batch_dst\n",
    "except NameError:\n",
    "  pass\n",
    "tf.reset_default_graph()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0MkktlHC5sh"
   },
   "outputs": [],
   "source": [
    "from converter.config import ColorCorrectionType\n",
    "\n",
    "config = ConverterConfig(\n",
    "    use_smoothed_bbox=True, use_kalman_filter=True,\n",
    "    use_auto_downscaling=False, bbox_moving_avg_coef=0.65,\n",
    "    min_face_area=35 * 35, kf_noise_coef=1e-3, color_correction=ColorCorrectionType.HISTMATCH,\n",
    "    detection_threshold=0.8, roi_coverage=0.9, enhance=0.0,\n",
    "    output_type=ImageOutputType.TRIPLE, direction=TransformDirection.AtoB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fd = MTCNNFaceDetector(sess=K.get_session(), model_path=\"./mtcnn_weights/\")\n",
    "vc = Converter(\"../mtcnn_weights/\", model_path=MODELS_DIR, session=K.get_session(), config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if config.direction == TransformDirection.AtoB:\n",
    "    input_fn = fn_source_video\n",
    "    output_fn = \"OUTPUT_VIDEO_AtoB.mp4\"\n",
    "    pass\n",
    "elif config.direction == TransformDirection.BtoA:\n",
    "    input_fn = fn_target_video\n",
    "    output_fn = \"OUTPUT_VIDEO_BtoA.mp4\"\n",
    "    pass\n",
    "\n",
    "duration = None  # None or a non-negative float tuple: (start_sec, end_sec). Duration of input video to be converted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "session = K.get_session()\n",
    "with session.as_default():\n",
    "    with session.graph.as_default():\n",
    "        vc.convert(input_fn, output_fn, duration=duration, audio=True)\n",
    "        pass\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Скачать результат (видеофайл)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    # noinspection PyUnresolvedReferences,PyPackageRequirements\n",
    "    from google.colab import files\n",
    "except ImportError:\n",
    "    print(\"This notebook can be run only in google colab\")\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwDUxwlL4voW"
   },
   "outputs": [],
   "source": [
    "if config.direction == TransformDirection.AtoB:\n",
    "    files.download(\"OUTPUT_VIDEO_AtoB.mp4\")\n",
    "    pass\n",
    "elif config.direction == TransformDirection.BtoA:\n",
    "    files.download(\"OUTPUT_VIDEO_BtoA.mp4\")\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "EJ1miHVk2ns7",
    "bSrt2h0K3so3"
   ],
   "name": "faceswap-demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}