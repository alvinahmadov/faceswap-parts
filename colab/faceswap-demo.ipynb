{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MiOo3478pJg9"
   },
   "source": [
    "# Приготовления\n",
    "\n",
    "Этот colab notebook является минимальной демонстрацией для Faceswap GAN.\n",
    "Поскольку colab допускает максимальное время работы 12 часов, мы будем\n",
    "обучать только облегченную модель в этом notebook.\n",
    "\n",
    "**Цель этой notebook - не обучить модель, которая дает высококачественные результаты, а дать краткий обзор того, как работает faceswap-GAN.**\n",
    "\n",
    "Порядок работы faceswap-GAN описан ниже:\n",
    "\n",
    "  1. Загрузите два видео для обучения;\n",
    "  2. Примените извлечение лица (предварительную обработку) к двум загруженным видео;\n",
    "  3. Тренируйте легкую модель для Faceswap GAN. (~10-12 ч.)\n",
    "  4. Примените преобразование видео к загруженным видео."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qf8Wvh5Wrm3V"
   },
   "source": [
    "# Шаг 1: Установите тип среды выполнения на Python 3/GPU\n",
    "Установите ноутбук colab в экземпляр GPU с помощью:\n",
    "**runtime -> change runtime type -> Python3 and GPU**\n",
    "\n",
    "В следующих ячейках будет отображена системная информация текущего экземпляра.\n",
    "Запустите ячейки и проверьте, использует ли он python > = 3.6 и имеет ли устройство GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1zQhhPfKrmQl",
    "outputId": "96b19dbd-91a1-4f32-b5a3-54bd8461b674"
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "1f96C1TApC00",
    "outputId": "eeeeac99-ae05-4aac-a237-77025a68eb4f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(f\"Tensorflow version {tf.version.VERSION}\")\n",
    "\n",
    "\n",
    "device_lib.list_local_devices()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Для выполнения кода в colab необходимо выполнить авторизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOsTN_gjzonZ"
   },
   "source": [
    "А также подключить Google Drive (или Google Storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "L4VioT5YpJQB",
    "outputId": "1824cbe3-1e3b-40c0-967f-27a30530fcb0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g_4C8o3y0DFD",
    "outputId": "73c9e73b-c5b2-40fe-a96c-1add0e4c70f2"
   },
   "outputs": [],
   "source": [
    "!mkdir -p /content/drive/MyDrive/faceswap_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K0wsds0OslRc"
   },
   "source": [
    "# Шаг 2: Клонируйте репозиторий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQ0HH6VUpJHW"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/alvinahmadov/faceswap-parts.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thlzp88qpJJk"
   },
   "outputs": [],
   "source": [
    "%cd \"faceswap-parts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyKu2hcCpJKu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Шаг 3: Загрузите видеоролики обучения\n",
    "\n",
    "Пользователь должен загрузить два видео: **source video** и **target video**.\n",
    "Модель **преобразует исходное лицо в целевое по умолчанию.**\n",
    "\n",
    "  - Видео, для лучшего результата должен **содержать только одного человека**.\n",
    "  - Ограничений по длине видео нет, но чем оно длиннее, тем больше времени потребуется\n",
    "на предварительную обработку/преобразование видео, что может привести к увеличению времени\n",
    "выполнения до 12 часов. (**Рекомендуемая продолжительность видео: 30 секунд ~ 2 минуты.**)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "try:\n",
    "    # noinspection PyUnresolvedReferences,PyPackageRequirements\n",
    "    from google.colab import files\n",
    "except:\n",
    "    print(\"This notebook can be run only in google colab\")\n",
    "    pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Можно использовать тестовые видео (выбирать только один способ)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "text",
    "id": "PS25Uu9kxDwo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fn_source_video=\"samples/source.mp4\"\n",
    "fn_target_video=\"samples/target.mp4\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BY3qysVq0p2P",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Или можно загрузить свои файлы для обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ym0EsJk9pJRw"
   },
   "outputs": [],
   "source": [
    "# Upload source video\n",
    "source_video = files.upload()\n",
    "\n",
    "for fn_source_video, _ in source_video.items():\n",
    "    print(fn_source_video)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otuzS3Di0gvz"
   },
   "outputs": [],
   "source": [
    "# Upload target video\n",
    "target_video = files.upload()\n",
    "\n",
    "for fn_target_video, _ in target_video.items():\n",
    "    print(fn_target_video)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kt5FVEt11B2K",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Шаг 4: Установите максимальное количество итераций обучения\n",
    "Для 25000 итераций по умолчанию требуется ~10 часов обучения.\n",
    "\n",
    "Итерации >= 27k могут превышать предельное время выполнения;\n",
    "Итерации < 18k могут привести к плохо обученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dO11aRsZ0gyK"
   },
   "outputs": [],
   "source": [
    "TOTAL_ITERS = 19000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIb9TSMz0g0g",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Шаг 5: Все готово.\n",
    "\n",
    "**Нажмите Ctrl + F10 (или runtime -> run after)**, чтобы запустить процесс. Для завершения\n",
    "тренировки потребуется 10 ~ 12 часов. Результирующее видео можно загрузить, запустив\n",
    "последнюю ячейку:\n",
    "  ```shell\n",
    "  files.download(\"OUTPUT_VIDEO.mp4\")\n",
    "  ```\n",
    "Обратите внимание, что **эту страницу не следует закрывать или обновлять во время работы**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "text",
    "id": "O9L5UW8U3AaQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%capture\n",
    "import imageio\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "imageio.plugins.ffmpeg.download()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WtyeXpEc2lDO"
   },
   "source": [
    "Отключаем стремительное исполнение (eager execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MtENXluJ0g2I",
    "outputId": "13491684-fc62-4021-c089-5921ae21df44"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFAokeU12Vff"
   },
   "outputs": [],
   "source": [
    "import tensorflow.python.keras.backend as K\n",
    "from detector import MTCNNFaceDetector\n",
    "import glob\n",
    "\n",
    "from preprocess import preprocess_video"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "text",
    "id": "EJ1miHVk2ns7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fd = MTCNNFaceDetector(sess=K.get_session(), model_path=\"./mtcnn_weights/\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjrPsIbZ2ViU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Устанавливаем константы для сохранения"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "text",
    "id": "bSrt2h0K3so3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "TRAIN_DIR=\"/content/drive/MyDrive/faceswap_train\"\n",
    "\n",
    "# Path to saved model weights\n",
    "MODELS_DIR=f\"{TRAIN_DIR}/models\"\n",
    "\n",
    "# Path to training images\n",
    "SAVE_PATH_SOURCE=f\"{TRAIN_DIR}/face_src\"\n",
    "SAVE_PATH_TARGET=f\"{TRAIN_DIR}/face_dst\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5o2dEVW92Vms",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Создаем директории для сохранения извлеченных данных, а также для моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiNsc3N_2VhU"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def makedirs(pathnames: list):\n",
    "    for pathname in pathnames:\n",
    "        Path(f\"{pathname}\").mkdir(parents=True, exist_ok=True)\n",
    "    pass\n",
    "\n",
    "for spath in [SAVE_PATH_SOURCE, SAVE_PATH_TARGET]:\n",
    "  makedirs([f\"{spath}/rgb\", f\"{spath}/binary_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_interval = 5 # perform face detection every {save_interval} frames\n",
    "\n",
    "preprocess_video(fn_source_video, fd, save_interval, f\"{SAVE_PATH_SOURCE}/\")\n",
    "preprocess_video(fn_target_video, fd, save_interval, f\"{SAVE_PATH_TARGET}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qvVr2TqI3jd9",
    "outputId": "0da0a7e2-4f07-4776-9d71-58cd9856dbc3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Получаем количество извлеченных данных"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "text",
    "id": "GexJ-i7c3vz2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "face_src_glob_len=str(len(glob.glob(f\"{SAVE_PATH_SOURCE}/rgb/*.*\")))\n",
    "face_dst_glob_len=str(len(glob.glob(f\"{SAVE_PATH_TARGET}/rgb/*.*\")))\n",
    "\n",
    "print(f\"{face_src_glob_len} face(s) extracted from source video: {fn_source_video}.\")\n",
    "print(f\"{face_dst_glob_len} face(s) extracted from target video: {fn_target_video}.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoCnWQiR3jgd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Следующие ячейки взяты из [faceswap_train_test.ipynb](https://github.com/alvinahmadov/faceswap-parts/blob/main/colab/faceswap_train_test.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjkSygNT3jjB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Импортируйте пакеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-KzKahMU3jlX"
   },
   "outputs": [],
   "source": [
    "import tensorflow.python.keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5fwrKth3jqO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ll7g7mGU3jss",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Конфигурация"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "text",
    "id": "x58lrjkw6iQM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "K.set_learning_phase(1)\n",
    "# Number of CPU cores\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "# Input/Output resolution\n",
    "RESOLUTION = 64  # 64x64, 128x128, 256x256\n",
    "assert (RESOLUTION % 64) == 0, \"RESOLUTION should be 64, 128, or 256.\"\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# Use motion blur (data augmentation)\n",
    "# set True if training data contains images extracted from videos\n",
    "use_da_motion_blur = False\n",
    "\n",
    "# Use eye-aware training\n",
    "# require images generated from prep_binary_masks.ipynb\n",
    "use_bm_eyes = True\n",
    "\n",
    "# Probability of random color matching (data augmentation)\n",
    "prob_random_color_match = 0.5\n",
    "\n",
    "da_config = {\n",
    "    \"prob_random_color_match\": prob_random_color_match,\n",
    "    \"use_da_motion_blur\": use_da_motion_blur,\n",
    "    \"use_bm_eyes\": use_bm_eyes\n",
    "}\n",
    "\n",
    "# Path to training images\n",
    "img_dir_src = f\"{SAVE_PATH_SOURCE}/rgb\" # source face\n",
    "img_dir_dst = f\"{SAVE_PATH_TARGET}/rgb\" # target face\n",
    "img_dir_src_bm_eyes = f\"{SAVE_PATH_SOURCE}/binary_mask\"\n",
    "img_dir_dst_bm_eyes = f\"{SAVE_PATH_TARGET}/binary_mask\"\n",
    "\n",
    "\n",
    "# Architecture configuration\n",
    "arch_config = {\n",
    "    \"IMAGE_SHAPE\": (RESOLUTION, RESOLUTION, 3),\n",
    "    \"use_self_attn\": True,\n",
    "    \"norm\": \"hybrid\",\n",
    "    \"model_capacity\": \"lite\"\n",
    "}\n",
    "\n",
    "# Loss function weights configuration\n",
    "loss_weights = {\n",
    "    \"w_D\": 0.1,\n",
    "    \"w_recon\": 1.,\n",
    "    \"w_edge\": 0.1,\n",
    "    \"w_eyes\": 30.,\n",
    "    \"w_pl\": (0.01, 0.1, 0.3, 0.1)\n",
    "}\n",
    "\n",
    "# Init. loss config.\n",
    "loss_config = {\n",
    "    \"gan_training\": \"mixup_LSGAN\",\n",
    "    \"use_PL\": False,\n",
    "    \"PL_before_activ\": True,\n",
    "    \"use_mask_hinge_loss\": False,\n",
    "    \"m_mask\": 0.,\n",
    "    \"lr_factor\": 1.,\n",
    "    \"use_cyclic_loss\": False\n",
    "}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOi2ZsSa4vf4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Постройте модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.faceswap_model import FaceswapModel\n",
    "from data_loader import DataLoader\n",
    "from utils import showG, showG_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4uUub3A4vi7"
   },
   "outputs": [],
   "source": [
    "model = FaceswapModel(**arch_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxwjrVoc4vmQ"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyuELtb94vpr"
   },
   "outputs": [],
   "source": [
    "!pip install keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sem7RMzm4vr6"
   },
   "outputs": [],
   "source": [
    "from vggface_models import RESNET50\n",
    "\n",
    "WEIGHTS_FILE=\"rcmalli_vggface_tf_notop_resnet50.h5\"\n",
    "\n",
    "vggface = RESNET50(include_top=False, weights=None, input_shape=(224, 224, 3))\n",
    "vggface.load_weights(WEIGHTS_FILE, by_name=True)\n",
    "\n",
    "model.build_pl_model(vggface_model=vggface, before_activ=loss_config[\"PL_before_activ\"])\n",
    "model.build_train_functions(loss_weights=loss_weights, **loss_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Начните тренировку"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create ./models directory\n",
    "Path(MODELS_DIR).mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get file names\n",
    "train_src = glob.glob(f\"{img_dir_src}/*.*\")\n",
    "train_dst = glob.glob(f\"{img_dir_dst}/*.*\")\n",
    "\n",
    "train_src_n_dst = train_src + train_dst\n",
    "\n",
    "assert len(train_src), f\"Изображение не найдено в {img_dir_src}\"\n",
    "assert len(train_dst), f\"Изображение не найдено в {img_dir_dst}\"\n",
    "print(f\"Количество изображений в папке A: {str(len(train_src))}\")\n",
    "print(f\"Количество изображений в папке B: {str(len(train_dst))}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_loss_config(loss_conf):\n",
    "    for config, value in loss_conf.items():\n",
    "        print(f\"{config} = {value}\")\n",
    "        pass\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reset_session(spath):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    spath : str\n",
    "     Save path\n",
    "    \"\"\"\n",
    "    global model, vggface\n",
    "    global train_batch_src, train_batch_dst\n",
    "    model.save_weights(path=spath)\n",
    "    del model\n",
    "    del vggface\n",
    "    del train_batch_src\n",
    "    del train_batch_dst\n",
    "    K.clear_session()\n",
    "    model = FaceswapModel(**arch_config)\n",
    "    model.load_weights(path=spath)\n",
    "    vggface = RESNET50(include_top=False, weights=None, input_shape=(224, 224, 3))\n",
    "    vggface.load_weights(\"rcmalli_vggface_tf_notop_resnet50.h5\")\n",
    "    model.build_pl_model(vggface_model=vggface, before_activ=loss_config[\"PL_before_activ\"])\n",
    "    train_batch_src = DataLoader(filenames=train_src, all_filenames=train_src_n_dst,\n",
    "                                 batch_size=batch_size, dir_bm_eyes=img_dir_src_bm_eyes,\n",
    "                                 resolution=RESOLUTION, num_cpus=num_cpus, session=K.get_session(),\n",
    "                                 **da_config)\n",
    "    train_batch_dst = DataLoader(filenames=train_dst, all_filenames=train_src_n_dst,\n",
    "                                 batch_size=batch_size, dir_bm_eyes=img_dir_dst_bm_eyes,\n",
    "                                 resolution=RESOLUTION, num_cpus=num_cpus, session=K.get_session(),\n",
    "                                 **da_config)\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Start training\n",
    "t0 = time.time()\n",
    "\n",
    "# This try/except is meant to resume training if we disconnected from Colab\n",
    "try:\n",
    "    # noinspection PyUnresolvedReferences,PyStatementEffect,PyUnboundLocalVariable\n",
    "    gen_iterations\n",
    "    # noinspection PyUnresolvedReferences,PyStatementEffect,PyUnboundLocalVariable\n",
    "    print(f\"Возобновить обучение c {gen_iterations} итерации.\")\n",
    "except:\n",
    "    gen_iterations = 0\n",
    "    pass\n",
    "\n",
    "errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n",
    "errGAs = {}\n",
    "errGBs = {}\n",
    "\n",
    "for k in ['ttl', 'adv', 'recon', 'edge', 'pl']:\n",
    "    errGAs[k] = 0\n",
    "    errGBs[k] = 0\n",
    "    pass\n",
    "\n",
    "display_iters = 300\n",
    "global TOTAL_ITERS\n",
    "global train_batch_src, train_batch_dst\n",
    "\n",
    "train_batch_src = DataLoader(train_src, train_src_n_dst, batch_size,\n",
    "                             dir_bm_eyes=img_dir_src_bm_eyes, resolution=RESOLUTION,\n",
    "                             num_cpus=num_cpus, session=K.get_session(), **da_config)\n",
    "\n",
    "train_batch_dst = DataLoader(train_dst, train_src_n_dst, batch_size,\n",
    "                             dir_bm_eyes=img_dir_dst_bm_eyes, resolution=RESOLUTION,\n",
    "                             num_cpus=num_cpus, session=K.get_session(), **da_config)\n",
    "\n",
    "while gen_iterations <= TOTAL_ITERS:\n",
    "    # Loss function automation\n",
    "    if gen_iterations == (TOTAL_ITERS // 5 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = False\n",
    "        loss_config['m_mask'] = 0.0\n",
    "        reset_session(MODELS_DIR)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (TOTAL_ITERS // 5 + TOTAL_ITERS // 10 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = True\n",
    "        loss_config['m_mask'] = 0.5\n",
    "        reset_session(MODELS_DIR)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Завершено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (2 * TOTAL_ITERS // 5 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = True\n",
    "        loss_config['m_mask'] = 0.2\n",
    "        reset_session(MODELS_DIR)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (TOTAL_ITERS // 2 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = True\n",
    "        loss_config['m_mask'] = 0.4\n",
    "        loss_config['lr_factor'] = 0.3\n",
    "        reset_session(MODELS_DIR)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (2 * TOTAL_ITERS // 3 - display_iters // 2):\n",
    "        clear_output()\n",
    "        model.decoder_src.load_weights(\"models/decoder_B.h5\")  # swap decoders\n",
    "        model.decoder_dst.load_weights(\"models/decoder_A.h5\")  # swap decoders\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = True\n",
    "        loss_config['m_mask'] = 0.5\n",
    "        loss_config['lr_factor'] = 1\n",
    "        reset_session(MODELS_DIR)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (8 * TOTAL_ITERS // 10 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = True\n",
    "        loss_config['m_mask'] = 0.1\n",
    "        loss_config['lr_factor'] = 0.3\n",
    "        reset_session(MODELS_DIR)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "        pass\n",
    "    elif gen_iterations == (9 * TOTAL_ITERS // 10 - display_iters // 2):\n",
    "        clear_output()\n",
    "        loss_config['use_PL'] = True\n",
    "        loss_config['use_mask_hinge_loss'] = False\n",
    "        loss_config['m_mask'] = 0.0\n",
    "        loss_config['lr_factor'] = 0.1\n",
    "        reset_session(MODELS_DIR)\n",
    "        print(\"Конструкция новых функций потерь...\")\n",
    "        show_loss_config(loss_config)\n",
    "        model.build_train_functions(loss_weights=loss_weights, **loss_config)\n",
    "        print(\"Выполнено.\")\n",
    "\n",
    "        pass\n",
    "\n",
    "    if gen_iterations == 5:\n",
    "        print(\"working.\")\n",
    "        pass\n",
    "\n",
    "    # Train dicriminators for one batch\n",
    "    data_src = train_batch_src.get_next_batch()\n",
    "    data_dst = train_batch_dst.get_next_batch()\n",
    "    errDA, errDB = model.train_one_batch_disc(data_src, data_dst)\n",
    "    errDA_sum += errDA[0]\n",
    "    errDB_sum += errDB[0]\n",
    "\n",
    "    # Train generators for one batch\n",
    "    data_src = train_batch_src.get_next_batch()\n",
    "    data_dst = train_batch_dst.get_next_batch()\n",
    "    errGA, errGB = model.train_one_batch_gen(data_src, data_dst)\n",
    "    errGA_sum += errGA[0]\n",
    "    errGB_sum += errGB[0]\n",
    "    for i, k in enumerate(['ttl', 'adv', 'recon', 'edge', 'pl']):\n",
    "        errGAs[k] += errGA[i]\n",
    "        errGBs[k] += errGB[i]\n",
    "        pass\n",
    "    gen_iterations += 1\n",
    "\n",
    "    # Visualization\n",
    "    if gen_iterations % display_iters == 0:\n",
    "        clear_output()\n",
    "\n",
    "        # Display loss information\n",
    "        show_loss_config(loss_config)\n",
    "        print(\"----------\")\n",
    "        print(\"[iter %d] Loss_DA: %f Loss_DB: %f Loss_GA: %f Loss_GB: %f time: %f\"\n",
    "              % (gen_iterations, errDA_sum / display_iters, errDB_sum / display_iters,\n",
    "                 errGA_sum / display_iters, errGB_sum / display_iters, time.time() - t0))\n",
    "        print(\"----------\")\n",
    "        print(\"Детали потерь генератора:\")\n",
    "        print(f\"[Adversarial loss]\\nGA: {errGAs['adv'] / display_iters:.4f} GB: {errGBs['adv'] / display_iters:.4f}\")\n",
    "        print(f\"[Reconstruction loss]\\nGA: {errGAs['recon'] / display_iters:.4f} GB: {errGBs['recon'] / display_iters:.4f}\")\n",
    "        print(f\"[Edge loss]\\nGA: {errGAs['edge'] / display_iters:.4f} GB: {errGBs['edge'] / display_iters:.4f}\")\n",
    "        if loss_config['use_PL']:\n",
    "            print(f\"[Perceptual loss]\")\n",
    "            try:\n",
    "                print(f\"GA: {errGAs['pl'][0] / display_iters:.4f} GB: {errGBs['pl'][0] / display_iters:.4f}\")\n",
    "            except:\n",
    "                print(f\"GA: {errGAs['pl'] / display_iters:.4f} GB: {errGBs['pl'] / display_iters:.4f}\")\n",
    "                pass\n",
    "            pass\n",
    "\n",
    "        # Display images\n",
    "        print(\"----------\")\n",
    "        w_src, t_src, _ = train_batch_src.get_next_batch()\n",
    "        w_dst, t_dst, _ = train_batch_dst.get_next_batch()\n",
    "        print(\"Преобразованные (замаскированные) результаты:\")\n",
    "        showG(t_src, t_dst, model.path_src, model.path_dst, batch_size)\n",
    "        print(\"Маски:\")\n",
    "        showG_mask(t_src, t_dst, model.path_mask_src, model.path_mask_dst, batch_size)\n",
    "        print(\"Результаты реконструкции:\")\n",
    "        showG(w_src, w_dst, model.path_bgr_src, model.path_bgr_dst, batch_size)\n",
    "        errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n",
    "        for k in ['ttl', 'adv', 'recon', 'edge', 'pl']:\n",
    "            errGAs[k] = 0\n",
    "            errGBs[k] = 0\n",
    "            pass\n",
    "\n",
    "        # Save models\n",
    "        model.save_weights(path=MODELS_DIR)\n",
    "        pass\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Конвертация видео\n",
    "[faceswap_video_conversion.ipynb](https://github.com/alvinahmadov/faceswap-parts/blob/main/colab/faceswap_video_conversion.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from converter import VideoConverter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "global model, vggface\n",
    "global train_batch_src, train_batch_b\n",
    "del model\n",
    "del vggface\n",
    "del train_batch_src\n",
    "del train_batch_dst\n",
    "tf.compat.v1.reset_default_graph()\n",
    "K.clear_session()\n",
    "model = FaceswapModel(**arch_config)\n",
    "model.load_weights(path=MODELS_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fd = MTCNNFaceDetector(sess=K.get_session(), model_path=\"./mtcnn_weights/\")\n",
    "vc = VideoConverter()\n",
    "vc.set_face_detector(fd)\n",
    "vc.set_gan_model(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "options = {\n",
    "    # ===== Fixed =====\n",
    "    \"use_smoothed_bbox\": True,\n",
    "    \"use_kalman_filter\": True,\n",
    "    \"use_auto_downscaling\": False,\n",
    "    \"bbox_moving_avg_coef\": 0.65,\n",
    "    \"min_face_area\": 35 * 35,\n",
    "    \"IMAGE_SHAPE\": model.image_shape,\n",
    "    # ===== Tunable =====\n",
    "    \"kf_noise_coef\": 1e-3,\n",
    "    \"use_color_correction\": \"hist_match\",\n",
    "    \"detec_threshold\": 0.8,\n",
    "    \"roi_coverage\": 0.9,\n",
    "    \"enhance\": 0.,\n",
    "    \"output_type\": 3,\n",
    "    \"direction\": \"AtoB\",  # determines the transform direction\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if options[\"direction\"] == \"AtoB\":\n",
    "    input_fn = fn_source_video\n",
    "    output_fn = \"OUTPUT_VIDEO_AtoB.mp4\"\n",
    "    pass\n",
    "elif options[\"direction\"] == \"BtoA\":\n",
    "    input_fn = fn_target_video\n",
    "    output_fn = \"OUTPUT_VIDEO_BtoA.mp4\"\n",
    "    pass\n",
    "\n",
    "duration = None  # None or a non-negative float tuple: (start_sec, end_sec). Duration of input video to be converted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# noinspection PyUnboundLocalVariable\n",
    "vc.convert(input_fn, output_fn, options, duration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwKOc5Jt5oFO"
   },
   "source": [
    "# Скачать результат (видеофайл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0MkktlHC5sh"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # noinspection PyUnresolvedReferences,PyPackageRequirements\n",
    "    from google.colab import files\n",
    "except:\n",
    "    print(\"This notebook can be run only in google colab\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwDUxwlL4voW"
   },
   "outputs": [],
   "source": [
    "if options[\"direction\"] == \"AtoB\":\n",
    "    files.download(\"OUTPUT_VIDEO_AtoB.mp4\")\n",
    "    pass\n",
    "elif options[\"direction\"] == \"BtoA\":\n",
    "    files.download(\"OUTPUT_VIDEO_BtoA.mp4\")\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "faceswap-GAN_lite_demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}